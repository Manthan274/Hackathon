{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:,1:].values.astype('float32') # all pixel values\n",
    "train_y = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "test = test.values.astype('float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "test=test.reshape(test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 1, 28, 28)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes =y_test.shape[1]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 42000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 84s 2ms/step - loss: 0.3018 - acc: 0.9148 - val_loss: 0.1093 - val_acc: 0.9687\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 84s 2ms/step - loss: 0.0894 - acc: 0.9732 - val_loss: 0.0606 - val_acc: 0.9824\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 78s 2ms/step - loss: 0.0613 - acc: 0.9813 - val_loss: 0.0376 - val_acc: 0.9892\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 80s 2ms/step - loss: 0.0480 - acc: 0.9856 - val_loss: 0.0349 - val_acc: 0.9903\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 79s 2ms/step - loss: 0.0397 - acc: 0.9879 - val_loss: 0.0308 - val_acc: 0.9904\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 78s 2ms/step - loss: 0.0330 - acc: 0.9895 - val_loss: 0.0190 - val_acc: 0.9948\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 73s 2ms/step - loss: 0.0271 - acc: 0.9914 - val_loss: 0.0148 - val_acc: 0.9958\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 73s 2ms/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0144 - val_acc: 0.9959\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 73s 2ms/step - loss: 0.0195 - acc: 0.9940 - val_loss: 0.0089 - val_acc: 0.9979\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 76s 2ms/step - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0093 - val_acc: 0.9974\n",
      "Baseline Error: 0.26%\n"
     ]
    }
   ],
   "source": [
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_train, y_train), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"test_predictions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 1, 28, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
